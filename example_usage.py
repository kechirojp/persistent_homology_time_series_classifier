"""
Example Usage of Persistent Homology Classifier

æŒç¶šãƒ›ãƒ¢ãƒ­ã‚¸ãƒ¼åˆ†é¡å™¨ã®ä½¿ç”¨ä¾‹ï¼ˆTDAã®ã¿ã€UMAPãªã—ï¼‰
"""

import numpy as np
import sys
import os

# ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from src import (
    TDAFeatureExtractor,
    signed_log_transform,
    create_sliding_windows,
    normalize_data,
    filter_prediction_points,
    evaluate_classification
)

from src.classifier_utils import (
    create_classification_signals,
    calculate_sequence_metrics
)

def generate_sample_data(n_samples: int = 240, n_features: int = 4) -> tuple:
    """
    ãƒ‡ãƒ‘ãƒ¼ãƒˆæœˆæ¬¡ãƒ‡ãƒ¼ã‚¿ã®ã‚µãƒ³ãƒ—ãƒ«ç”Ÿæˆï¼ˆ20å¹´åˆ† = 240ãƒ¶æœˆï¼‰
    
    ã€å…·ä½“ä¾‹ï¼šãƒ‡ãƒ‘ãƒ¼ãƒˆã®æœˆæ¬¡å–¶æ¥­ãƒ‡ãƒ¼ã‚¿ã€‘
    - ç‰¹å¾´é‡0ï¼šãƒ¡ã‚¤ãƒ³å£²ä¸Šï¼ˆé£Ÿå“ã€è¡£æ–™å“ã€é›‘è²¨ãªã©ï¼‰ç™¾ä¸‡å††
    - ç‰¹å¾´é‡1ï¼šé–¢é€£å•†å“å£²ä¸Šï¼ˆã‚¤ãƒ™ãƒ³ãƒˆå•†å“ã€å­£ç¯€å•†å“ãªã©ï¼‰ç™¾ä¸‡å††  
    - ç‰¹å¾´é‡2ï¼šæ¥å®¢æ•°ï¼ˆæœˆé–“å»¶ã¹æ¥å®¢æ•°ï¼‰åƒäºº
    - ç‰¹å¾´é‡3ï¼šå–¶æ¥­æ™‚é–“ï¼ˆæœˆé–“ç·å–¶æ¥­æ™‚é–“ï¼‰æ™‚é–“
    
    ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼š
    - é€šå¸¸æœŸï¼š12ãƒ¶æœˆå‘¨æœŸã®å­£ç¯€å¤‰å‹•ï¼ˆæ˜¥å¤ç§‹å†¬ï¼‰
    - ç‰¹åˆ¥æœŸï¼šå¹´æœ«å¹´å§‹ã€GWã€ãŠç›†ã®å£²ä¸Šå¢—
    - ç•°å¸¸æœŸï¼šã‚³ãƒ­ãƒŠç¦ï¼ˆ2020å¹´ï¼‰ã‚„ãƒªãƒ‹ãƒ¥ãƒ¼ã‚¢ãƒ«å·¥äº‹æœŸé–“
    
    Returns:
    --------
    data : np.ndarray
        ãƒ‡ãƒ‘ãƒ¼ãƒˆæœˆæ¬¡ãƒ‡ãƒ¼ã‚¿ (240, 4)
    labels : np.ndarray  
        æœŸé–“ãƒ©ãƒ™ãƒ« (0:é€šå¸¸æœŸ, 1:ç‰¹åˆ¥æœŸ, 2:ç•°å¸¸æœŸ)
    """
    np.random.seed(42)
    
    # 20å¹´é–“ï¼ˆ240ãƒ¶æœˆï¼‰ã®æœˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
    months = np.arange(240)
    data = np.zeros((240, 4))
    labels = np.zeros(240, dtype=int)
    
    for i, month in enumerate(months):
        year = 2000 + month // 12  # 2000å¹´ã‹ã‚‰é–‹å§‹
        month_of_year = month % 12 + 1  # 1-12æœˆ
        
        # === åŸºæœ¬çš„ãªå­£ç¯€ãƒ‘ã‚¿ãƒ¼ãƒ³ ===
        # å­£ç¯€ä¿‚æ•°ï¼ˆæ˜¥å¤ç§‹å†¬ï¼‰
        seasonal_factor = 1.0 + 0.3 * np.sin(2 * np.pi * month / 12)
        
        # å¹´æœ«å•†æˆ¦ãƒ–ãƒ¼ã‚¹ãƒˆï¼ˆ12æœˆã€1æœˆï¼‰
        if month_of_year in [12, 1]:
            seasonal_factor *= 1.8
            labels[i] = 1  # ç‰¹åˆ¥æœŸ
        # GWãƒ»ãŠç›†ãƒ–ãƒ¼ã‚¹ãƒˆï¼ˆ5æœˆã€8æœˆï¼‰
        elif month_of_year in [5, 8]:
            seasonal_factor *= 1.4
            labels[i] = 1  # ç‰¹åˆ¥æœŸ
        else:
            labels[i] = 0  # é€šå¸¸æœŸ
            
        # === ç•°å¸¸æœŸé–“ã®è¨­å®š ===
        # ã‚³ãƒ­ãƒŠç¦ï¼ˆ2020å¹´3æœˆ-2021å¹´12æœˆï¼‰
        if 2020 <= year <= 2021:
            if year == 2020 and month_of_year >= 3:
                seasonal_factor *= 0.4  # å£²ä¸Šå¤§å¹…æ¸›
                labels[i] = 2  # ç•°å¸¸æœŸ
            elif year == 2021:
                seasonal_factor *= 0.7  # å›å¾©é€”ä¸Š
                labels[i] = 2  # ç•°å¸¸æœŸ
                
        # ãƒªãƒ‹ãƒ¥ãƒ¼ã‚¢ãƒ«å·¥äº‹ï¼ˆ2010å¹´6-8æœˆï¼‰
        if year == 2010 and month_of_year in [6, 7, 8]:
            seasonal_factor *= 0.2  # å–¶æ¥­åœæ­¢çŠ¶æ…‹
            labels[i] = 2  # ç•°å¸¸æœŸ
            
        # === å„ç‰¹å¾´é‡ã®ç”Ÿæˆ ===
        base_noise = np.random.normal(0, 0.1, 4)
        
        # ç‰¹å¾´é‡0: ãƒ¡ã‚¤ãƒ³å£²ä¸Šï¼ˆåŸºæº–å€¤500ç™¾ä¸‡å††ï¼‰
        data[i, 0] = 500 * seasonal_factor + base_noise[0] * 50
        
        # ç‰¹å¾´é‡1: é–¢é€£å•†å“å£²ä¸Šï¼ˆãƒ¡ã‚¤ãƒ³å£²ä¸Šã®30-50%ï¼‰
        relation_ratio = 0.4 + 0.1 * np.sin(2 * np.pi * month / 6)  # åŠå¹´å‘¨æœŸ
        data[i, 1] = data[i, 0] * relation_ratio + base_noise[1] * 20
        
        # ç‰¹å¾´é‡2: æ¥å®¢æ•°ï¼ˆåŸºæº–å€¤100åƒäººï¼‰
        customer_factor = seasonal_factor * (1 + 0.2 * np.cos(2 * np.pi * month / 12))
        data[i, 2] = 100 * customer_factor + base_noise[2] * 10
        
        # ç‰¹å¾´é‡3: å–¶æ¥­æ™‚é–“ï¼ˆåŸºæº–å€¤300æ™‚é–“/æœˆï¼‰
        # ç•°å¸¸æœŸã¯å–¶æ¥­æ™‚é–“çŸ­ç¸®
        if labels[i] == 2:  # ç•°å¸¸æœŸ
            hour_factor = 0.7  # å–¶æ¥­æ™‚é–“çŸ­ç¸®
        else:
            hour_factor = 1.0
        data[i, 3] = 300 * hour_factor + base_noise[3] * 5
    
    return data, labels


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("=== æŒç¶šãƒ›ãƒ¢ãƒ­ã‚¸ãƒ¼åˆ†é¡å™¨ã®ä½¿ç”¨ä¾‹ ===\n")
    
    # 1. ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
    print("1. ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆä¸­...")
    data, labels = generate_sample_data(n_samples=500, n_features=6)
    print(f"ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: {data.shape}")
    print(f"ãƒ©ãƒ™ãƒ«åˆ†å¸ƒ: Class A={np.sum(labels==0)}, Class B={np.sum(labels==1)}, Neutral={np.sum(labels==2)}")
    
    # 2. ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†
    print("\n2. ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ä¸­...")
    
    # æ­£è² ç¬¦å·ä»˜ãå¯¾æ•°å¤‰æ›
    data_transformed = signed_log_transform(data)
    print(f"å¯¾æ•°å¤‰æ›å¾Œå½¢çŠ¶: {data_transformed.shape}")
    
    # æ­£è¦åŒ–
    data_normalized, scaler_params = normalize_data(data_transformed, method='zscore')
    print(f"æ­£è¦åŒ–å¾Œå½¢çŠ¶: {data_normalized.shape}")
    
    # 3. ã‚¹ãƒ©ã‚¤ãƒ‡ã‚£ãƒ³ã‚°ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ä½œæˆ
    print("\n3. ã‚¹ãƒ©ã‚¤ãƒ‡ã‚£ãƒ³ã‚°ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ä½œæˆä¸­...")
    windows, window_labels = create_sliding_windows(
        data_normalized, 
        window_size=40, 
        step_size=5,
        labels=labels
    )
    print(f"ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦å½¢çŠ¶: {windows.shape}")
    print(f"ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ãƒ©ãƒ™ãƒ«å½¢çŠ¶: {window_labels.shape}")
    
    # 4. TDAç‰¹å¾´æŠ½å‡º
    print("\n4. TDAç‰¹å¾´æŠ½å‡ºä¸­...")
def main():
    """
    ãƒ‡ãƒ‘ãƒ¼ãƒˆæœˆæ¬¡ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ã£ãŸæŒç¶šãƒ›ãƒ¢ãƒ­ã‚¸ãƒ¼åˆ†æã®ãƒ‡ãƒ¢
    """
    print("ğŸ¬ ãƒ‡ãƒ‘ãƒ¼ãƒˆæœˆæ¬¡ãƒ‡ãƒ¼ã‚¿ã®æŒç¶šãƒ›ãƒ¢ãƒ­ã‚¸ãƒ¼åˆ†æãƒ‡ãƒ¢")
    print("=" * 60)
    
    # 1. ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
    print("1. ãƒ‡ãƒ‘ãƒ¼ãƒˆæœˆæ¬¡ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆä¸­...")
    print("   ğŸ“… æœŸé–“: 2000å¹´1æœˆ - 2019å¹´12æœˆï¼ˆ20å¹´é–“ã€240ãƒ¶æœˆï¼‰")
    print("   ğŸ“Š ç‰¹å¾´é‡: ãƒ¡ã‚¤ãƒ³å£²ä¸Šã€é–¢é€£å•†å“å£²ä¸Šã€æ¥å®¢æ•°ã€å–¶æ¥­æ™‚é–“")
    
    data, labels = generate_sample_data()
    print(f"   ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: {data.shape}")
    
    # ãƒ©ãƒ™ãƒ«ã®å†…è¨³ã‚’è¡¨ç¤º
    label_names = ['é€šå¸¸æœŸ', 'ç‰¹åˆ¥æœŸ', 'ç•°å¸¸æœŸ']
    for i, name in enumerate(label_names):
        count = np.sum(labels == i)
        print(f"   {name}: {count}ãƒ¶æœˆ")
    
    # 2. ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†
    print("\n2. ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ä¸­...")
    
    # å¯¾æ•°å¤‰æ›ï¼ˆå£²ä¸Šãƒ‡ãƒ¼ã‚¿ã®æ­ªã¿ã‚’ä¿®æ­£ï¼‰
    data_transformed = signed_log_transform(data)
    print("   âœ… å¯¾æ•°å¤‰æ›å®Œäº†")
    
    # æ­£è¦åŒ–
    data_normalized, scaler = normalize_data(data_transformed, method='zscore')
    print("   âœ… Z-scoreæ­£è¦åŒ–å®Œäº†")
    
    # æ»‘ã‚‰ã‹ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ä½œæˆï¼ˆ12ãƒ¶æœˆçª“ã§å¹´å˜ä½åˆ†æï¼‰
    window_size = 12  # 12ãƒ¶æœˆ = 1å¹´é–“ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è¦‹ã‚‹
    windows, window_labels = create_sliding_windows(
        data_normalized, 
        window_size=window_size,
        step_size=1
    )
    print(f"   âœ… {len(windows)}å€‹ã®12ãƒ¶æœˆçª“ã‚’ä½œæˆ")
    
    # 3. TDAç‰¹å¾´æŠ½å‡º
    print("\n3. æŒç¶šãƒ›ãƒ¢ãƒ­ã‚¸ãƒ¼åˆ†æä¸­...")
    
    tda_extractor = TDAFeatureExtractor(
        embedding_dim=3,          # 3æ¬¡å…ƒåŸ‹ã‚è¾¼ã¿
        tau=1,                    # é…å»¶æ™‚é–“
        max_edge_length=2.0,      # ã‚¨ãƒƒã‚¸æœ€å¤§è·é›¢
        persistence_threshold=0.1  # æŒç¶šæ€§é–¾å€¤
    )
    
    print("   ğŸ” å„12ãƒ¶æœˆçª“ã®birth-deathåˆ†æå®Ÿè¡Œä¸­...")
    
    try:
        tda_features, components = tda_extractor.extract_features(
            windows[:100],  # æœ€åˆã®100çª“ã®ã¿ï¼ˆè¨ˆç®—æ™‚é–“çŸ­ç¸®ï¼‰
            return_components=True
        )
        
        print(f"   âœ… TDAç‰¹å¾´æŠ½å‡ºå®Œäº†: {tda_features.shape}")
        
        # æŒç¶šæ€§ã‚¹ã‚³ã‚¢ã‚’å–å¾—
        persistence_scores = components['pd_scores'].flatten()
        simplex_features = components['simplex_tree_features']
        
        print(f"   ğŸ“ˆ æŒç¶šæ€§ã‚¹ã‚³ã‚¢: å¹³å‡={persistence_scores.mean():.3f}, æ¨™æº–åå·®={persistence_scores.std():.3f}")
        
    except Exception as e:
        print(f"   âŒ TDAç‰¹å¾´æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
        return
    
    # 4. ç•°å¸¸æ¤œçŸ¥åˆ†æ
    print("\n4. ç•°å¸¸æ¤œçŸ¥åˆ†æä¸­...")
    
    # ä½ã„æŒç¶šæ€§ = ç•°å¸¸ã¨åˆ¤å®š
    anomaly_threshold = np.percentile(persistence_scores, 10)  # ä¸‹ä½10%
    anomalies = persistence_scores < anomaly_threshold
    
    print(f"   ğŸ¯ ç•°å¸¸åˆ¤å®šé–¾å€¤: {anomaly_threshold:.3f}")
    print(f"   ğŸš¨ æ¤œå‡ºã•ã‚ŒãŸç•°å¸¸çª“: {np.sum(anomalies)}/{len(anomalies)}")
    
    # ç•°å¸¸çª“ã®è©³ç´°è¡¨ç¤º
    anomaly_indices = np.where(anomalies)[0]
    if len(anomaly_indices) > 0:
        print("   ğŸ“‹ ç•°å¸¸æ¤œå‡ºã•ã‚ŒãŸæœŸé–“:")
        for idx in anomaly_indices[:5]:  # æœ€åˆã®5ã¤ã ã‘è¡¨ç¤º
            start_month = idx + 1  # 1å§‹ã¾ã‚Š
            end_month = start_month + 11
            start_year = 2000 + (start_month - 1) // 12
            end_year = 2000 + (end_month - 1) // 12
            print(f"      - {start_year}å¹´{(start_month-1)%12+1}æœˆã€œ{end_year}å¹´{(end_month-1)%12+1}æœˆ (æŒç¶šæ€§: {persistence_scores[idx]:.3f})")
    
    # 5. æ§‹é€ åˆ†æ
    print("\n5. ãƒ‡ãƒ¼ã‚¿æ§‹é€ åˆ†æ...")
    
    # å„æ¬¡å…ƒã®çµ±è¨ˆ
    print("   ğŸï¸ 0æ¬¡å…ƒï¼ˆé€£çµæˆåˆ†ï¼‰:")
    betti_0 = simplex_features[:, 2]  # betti_0ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
    print(f"      å¹³å‡: {betti_0.mean():.2f}, ç¯„å›²: {betti_0.min():.0f}-{betti_0.max():.0f}")
    
    print("   ğŸ”„ 1æ¬¡å…ƒï¼ˆå‘¨æœŸæ§‹é€ ï¼‰:")
    betti_1 = simplex_features[:, 3]  # betti_1ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹  
    print(f"      å¹³å‡: {betti_1.mean():.2f}, ç¯„å›²: {betti_1.min():.0f}-{betti_1.max():.0f}")
    
    # 6. çµæœã‚µãƒãƒªãƒ¼
    print("\n" + "=" * 60)
    print("ğŸ“Š åˆ†æçµæœã‚µãƒãƒªãƒ¼")
    print("=" * 60)
    print(f"ğŸ¬ å¯¾è±¡æœŸé–“: 20å¹´é–“ï¼ˆ240ãƒ¶æœˆï¼‰ã®ãƒ‡ãƒ‘ãƒ¼ãƒˆå–¶æ¥­ãƒ‡ãƒ¼ã‚¿")
    print(f"ğŸ” åˆ†æçª“æ•°: {len(windows)}å€‹ã®12ãƒ¶æœˆçª“")
    print(f"ğŸ“ˆ å¹³å‡æŒç¶šæ€§: {persistence_scores.mean():.3f}")
    print(f"ğŸš¨ ç•°å¸¸æ¤œå‡º: {np.sum(anomalies)}çª“ï¼ˆ{100*np.sum(anomalies)/len(anomalies):.1f}%ï¼‰")
    print(f"â­ æ§‹é€ å®‰å®šæ€§: {'é«˜' if persistence_scores.std() < 0.5 else 'ä¸­' if persistence_scores.std() < 1.0 else 'ä½'}")
    
    print("\nâœ… åˆ†æå®Œäº†ï¼")
    print("ğŸ’¡ ãƒ’ãƒ³ãƒˆ: æŒç¶šæ€§ãŒä½ã„æœŸé–“ã¯æ§‹é€ çš„ãªå¤‰åŒ–ï¼ˆç•°å¸¸ï¼‰ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")
    
    return {
        'data': data,
        'labels': labels,
        'windows': windows,
        'tda_features': tda_features,
        'persistence_scores': persistence_scores,
        'anomalies': anomalies
    }


if __name__ == "__main__":
    results = main()
